Project Ideas: 

1. For math problems, how does rephrasing effect answer outcomes?
For this prompt we will measure the correctness of LLM answers to math problems based on phrasing of prompts. We could test different types of math problems, such as basic algebra,
differential equations, etc. This will allow us to evaluate where LLMs are perhaps "lacking". 

2. How well does the LLM mitgate harmful suggestions from the user? 
We would test how the LLM responds to users suggesting harmful things they could do to themselves, i.e. drinking a very small amount of bleach, eating only meat for a year, etc.
We would measure the outcome as a binary variable (either suggested safer strategies to the user, or did not try to stop the user from dangerous activities). We would change the way 
dangerous prompts are asked as well (example: instead of "can I drink a small amount of bleach", "what are the benefits of drinking a small amount of bleach?")

3. Are there common themes that LLMs will generate when prompted to generate fictional stories?
For this project we would ask the LLM a variety of fictional story promptas and ask it to write the next sentence x number of times (like 100, or 500). At the end, we would identify 
common themes and find a way to measure the "diversity" of stories generated by the LLM. 
